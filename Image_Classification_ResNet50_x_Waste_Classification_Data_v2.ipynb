{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raz0rGithub/CSIRE/blob/main/Image_Classification_ResNet50_x_Waste_Classification_Data_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IFG9ogbhqAN"
      },
      "source": [
        "# **Setup**: imports, seeds, & dataset downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aNoKmiJaZQf",
        "outputId": "12207d97-7e11-482a-8c07-d0439d2dde48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.12.0+cu113 (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP1Jokoza765"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wlYM20Ea9y_",
        "outputId": "dde0cf1f-d026-497b-8c08-7d774de17ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Downloading waste-classification-data-v2.zip to /content\n",
            " 97% 218M/226M [00:04<00:00, 44.6MB/s]\n",
            "100% 226M/226M [00:04<00:00, 57.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = 'victorckaggle'\n",
        "os.environ['KAGGLE_KEY'] = '9336857b8bc61c71ca7a7db2df7f364a'\n",
        "\n",
        "!pip install kaggle\n",
        "!kaggle datasets download sapal6/waste-classification-data-v2 --unzip\n",
        "\n",
        "ROOT = '/content'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL0q-TPtjblF"
      },
      "source": [
        "# **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJlZ_2kZQNvg"
      },
      "outputs": [],
      "source": [
        "data_dir = os.path.join(ROOT, 'DATASET')\n",
        "train_dir = os.path.join(data_dir, 'TRAIN')\n",
        "test_dir = os.path.join(data_dir, 'TEST')\n",
        "images_dir = os.path.join(data_dir, 'TRAIN')\n",
        "\n",
        "classes = os.listdir(images_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9LuLWq5544G"
      },
      "outputs": [],
      "source": [
        "# train_data = datasets.ImageFolder(root = train_dir, transform = transforms.ToTensor())\n",
        "\n",
        "# means = torch.zeros(3)\n",
        "# stds = torch.zeros(3)\n",
        "\n",
        "# for img, label in train_data:\n",
        "#     means += torch.mean(img, dim = (1,2))\n",
        "#     stds += torch.std(img, dim = (1,2))\n",
        "\n",
        "# means /= len(train_data)\n",
        "# stds /= len(train_data)\n",
        "    \n",
        "# print(f'Calculated means: {means}')\n",
        "# print(f'Calculated stds: {stds}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8BqInOhmhnb"
      },
      "source": [
        "Pretrained values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4XOnbtHlt0w"
      },
      "outputs": [],
      "source": [
        "pretrained_size = 224\n",
        "pretrained_means = [0.6892, 0.6416, 0.5667]\n",
        "pretrained_stds= [0.2142, 0.2238, 0.2451]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.RandomRotation(5),\n",
        "                           transforms.RandomHorizontalFlip(0.5),\n",
        "                           transforms.RandomCrop(pretrained_size, padding = 10),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = pretrained_means, \n",
        "                                                std = pretrained_stds)\n",
        "                       ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.CenterCrop(pretrained_size),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = pretrained_means, \n",
        "                                                std = pretrained_stds)\n",
        "                       ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MFHFDNClzNY"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.ImageFolder(root = train_dir, \n",
        "                                  transform = train_transforms)\n",
        "\n",
        "test_data = datasets.ImageFolder(root = test_dir, \n",
        "                                 transform = test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63PplDyLmAif"
      },
      "outputs": [],
      "source": [
        "VALID_RATIO = 0.9\n",
        "\n",
        "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
        "n_valid_examples = len(train_data) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(train_data, \n",
        "                                           [n_train_examples, n_valid_examples])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh1Euw1EmCJ8"
      },
      "outputs": [],
      "source": [
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBm764HqmEBs",
        "outputId": "693d7a6d-3bea-4096-99c2-ae27f0ce0882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 20307\n",
            "Number of validation examples: 2257\n",
            "Number of testing examples: 2908\n",
            "Total: 25472\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "total = len(test_data) + len(train_data) + len(valid_data)\n",
        "print(f'Total: {total}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7C2z3JvmIP-"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator = data.DataLoader(train_data, \n",
        "                                 shuffle = True, \n",
        "                                 batch_size = BATCH_SIZE)\n",
        "\n",
        "valid_iterator = data.DataLoader(valid_data, \n",
        "                                 batch_size = BATCH_SIZE)\n",
        "\n",
        "test_iterator = data.DataLoader(test_data, \n",
        "                                batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKLalPFZad_D"
      },
      "source": [
        "# Plot Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrLpsHf7maws"
      },
      "outputs": [],
      "source": [
        "def normalize_image(image):\n",
        "    image_min = image.min()\n",
        "    image_max = image.max()\n",
        "    image.clamp_(min = image_min, max = image_max)\n",
        "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
        "    return image    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGj4lX6vaTG6"
      },
      "outputs": [],
      "source": [
        "# def plot_images(images, labels, classes, normalize = True):\n",
        "\n",
        "#     n_images = len(images)\n",
        "\n",
        "#     rows = int(np.sqrt(n_images))\n",
        "#     cols = int(np.sqrt(n_images))\n",
        "\n",
        "#     fig = plt.figure(figsize = (15, 15))\n",
        "\n",
        "#     for i in range(rows*cols):\n",
        "\n",
        "#         ax = fig.add_subplot(rows, cols, i+1)\n",
        "        \n",
        "#         image = images[i]\n",
        "\n",
        "#         if normalize:\n",
        "#             image = normalize_image(image)\n",
        "\n",
        "#         ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
        "#         label = classes[labels[i]]\n",
        "#         ax.set_title(label)\n",
        "#         ax.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upd6kjzKabFv"
      },
      "outputs": [],
      "source": [
        "# N_IMAGES = 25\n",
        "\n",
        "# images, labels = zip(*[(image, label) for image, label in \n",
        "#                            [train_data[i] for i in range(N_IMAGES)]])\n",
        "\n",
        "# classes = test_data.classes\n",
        "\n",
        "# plot_images(images, labels, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FVtmOgScemf"
      },
      "outputs": [],
      "source": [
        "# REFORMATING\n",
        "# def format_label(label):\n",
        "#     label = label.split('.')[-1]\n",
        "#     label = label.replace('_', ' ')\n",
        "#     label = label.title()\n",
        "#     label = label.replace(' ', '')\n",
        "#     return label\n",
        "\n",
        "# test_data.classes = [format_label(c) for c in test_data.classes]\n",
        "\n",
        "# classes = test_data.classes\n",
        "\n",
        "# plot_images(images, labels, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7tFyP0weNJf"
      },
      "source": [
        "# Architechture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lNi2s8iePNK"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "            \n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        \n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "        \n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "    \n",
        "        layers = []\n",
        "        \n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        \n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        \n",
        "        return x, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8E3avxyeSeM"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
        "                               stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "                        \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxqG5vKZeVe-"
      },
      "outputs": [],
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbKrBpmeeb3_"
      },
      "outputs": [],
      "source": [
        "resnet18_config = ResNetConfig(block = BasicBlock,\n",
        "                               n_blocks = [2,2,2,2],\n",
        "                               channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet34_config = ResNetConfig(block = BasicBlock,\n",
        "                               n_blocks = [3,4,6,3],\n",
        "                               channels = [64, 128, 256, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZwnJ5TOedUa"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \n",
        "    expansion = 4\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "    \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
        "                               stride = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
        "                               stride = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, \n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "            \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "                \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "            \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "    \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBj8jqCMefJv"
      },
      "outputs": [],
      "source": [
        "resnet50_config = ResNetConfig(block = Bottleneck,\n",
        "                               n_blocks = [3, 4, 6, 3],\n",
        "                               channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet101_config = ResNetConfig(block = Bottleneck,\n",
        "                                n_blocks = [3, 4, 23, 3],\n",
        "                                channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet152_config = ResNetConfig(block = Bottleneck,\n",
        "                                n_blocks = [3, 8, 36, 3],\n",
        "                                channels = [64, 128, 256, 512])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KBXjAusdhoG"
      },
      "source": [
        "# Active Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "971af6b9eb044275a29e83c76126c572",
            "2291a6be364f4d63b37d8b8e3e636766",
            "c5b7a7bfd40e4a158e0b70a3e7e0988f",
            "c4728cb6e25f42e7bcc8eaec072c420a",
            "5473d9ddbd06425c909e3b1815d877d3",
            "f709c7b385c14941a2941db586d8c677",
            "1e53c5a33b524b9dac7f8b7962e1cf30",
            "cef0fe32be564abe804987a498a7fcd6",
            "fe373a67416249dab8acbc0b213c7416",
            "b5a86dd671d949fcaa76922a43477c69",
            "7645f7f1521440b48e4e678f5bf65912"
          ]
        },
        "id": "fCCxOgZCeo_s",
        "outputId": "9a72747a-5415-43c2-b0ad-8a11ba541b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "971af6b9eb044275a29e83c76126c572"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pretrained_model = models.resnet50(pretrained = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrsgRBBGezJR",
        "outputId": "c3775fb2-6a01-40e4-c35f-10daff71b196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(pretrained_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8rcE-IHe6ZF"
      },
      "outputs": [],
      "source": [
        "IN_FEATURES = pretrained_model.fc.in_features \n",
        "OUTPUT_DIM = len(test_data.classes)\n",
        "\n",
        "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcn6oGmTe-LS"
      },
      "outputs": [],
      "source": [
        "pretrained_model.fc = fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlDS1VFWfA2-"
      },
      "outputs": [],
      "source": [
        "model = ResNet(resnet50_config, OUTPUT_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeJDht-v2Agd"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "  if \"fc\" in name or \"avgpool\" in name:\n",
        "    param.requires_grad = True\n",
        "  else:\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMAj-tLNfDOM",
        "outputId": "b352fc03-41a3-4cd8-bdc6-49193aa83475"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.load_state_dict(pretrained_model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsi0SLg-fErd",
        "outputId": "b18710e5-ff64-4531-d787-1d1447b462b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 6,147 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIdcGfYmiBJv"
      },
      "source": [
        "# Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjBShRyjfZVz"
      },
      "outputs": [],
      "source": [
        "# START_LR = 1e-7\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAcmf6S6fdr5"
      },
      "outputs": [],
      "source": [
        "# class LRFinder:\n",
        "#     def __init__(self, model, optimizer, criterion, device):\n",
        "        \n",
        "#         self.optimizer = optimizer\n",
        "#         self.model = model\n",
        "#         self.criterion = criterion\n",
        "#         self.device = device\n",
        "        \n",
        "#         torch.save(model.state_dict(), 'init_params.pt')\n",
        "\n",
        "#     def range_test(self, iterator, end_lr = 10, num_iter = 100, \n",
        "#                    smooth_f = 0.05, diverge_th = 5):\n",
        "        \n",
        "#         lrs = []\n",
        "#         losses = []\n",
        "#         best_loss = float('inf')\n",
        "\n",
        "#         lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
        "        \n",
        "#         iterator = IteratorWrapper(iterator)\n",
        "        \n",
        "#         for iteration in range(num_iter):\n",
        "\n",
        "#             loss = self._train_batch(iterator)\n",
        "\n",
        "#             #update lr\n",
        "#             lr_scheduler.step()\n",
        "            \n",
        "#             lrs.append(lr_scheduler.get_lr()[0])\n",
        "\n",
        "#             if iteration > 0:\n",
        "#                 loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
        "                \n",
        "#             if loss < best_loss:\n",
        "#                 best_loss = loss\n",
        "\n",
        "#             losses.append(loss)\n",
        "            \n",
        "#             if loss > diverge_th * best_loss:\n",
        "#                 print(\"Stopping early, the loss has diverged\")\n",
        "#                 break\n",
        "                       \n",
        "#         #reset model to initial parameters\n",
        "#         model.load_state_dict(torch.load('init_params.pt'))\n",
        "                    \n",
        "#         return lrs, losses\n",
        "\n",
        "#     def _train_batch(self, iterator):\n",
        "        \n",
        "#         self.model.train()\n",
        "        \n",
        "#         self.optimizer.zero_grad()\n",
        "        \n",
        "#         x, y = iterator.get_batch()\n",
        "        \n",
        "#         x = x.to(self.device)\n",
        "#         y = y.to(self.device)\n",
        "        \n",
        "#         y_pred, _ = self.model(x)\n",
        "                \n",
        "#         loss = self.criterion(y_pred, y)\n",
        "        \n",
        "#         loss.backward()\n",
        "        \n",
        "#         self.optimizer.step()\n",
        "        \n",
        "#         return loss.item()\n",
        "\n",
        "# class ExponentialLR(_LRScheduler):\n",
        "#     def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "#         self.end_lr = end_lr\n",
        "#         self.num_iter = num_iter\n",
        "#         super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "#     def get_lr(self):\n",
        "#         curr_iter = self.last_epoch + 1\n",
        "#         r = curr_iter / self.num_iter\n",
        "#         return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
        "\n",
        "# class IteratorWrapper:\n",
        "#     def __init__(self, iterator):\n",
        "#         self.iterator = iterator\n",
        "#         self._iterator = iter(iterator)\n",
        "\n",
        "#     def __next__(self):\n",
        "#         try:\n",
        "#             inputs, labels = next(self._iterator)\n",
        "#         except StopIteration:\n",
        "#             self._iterator = iter(self.iterator)\n",
        "#             inputs, labels, *_ = next(self._iterator)\n",
        "\n",
        "#         return inputs, labels\n",
        "\n",
        "#     def get_batch(self):\n",
        "#         return next(self)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjzTxGiifgQS"
      },
      "outputs": [],
      "source": [
        "# END_LR = 50\n",
        "# NUM_ITER = 50\n",
        "\n",
        "# lr_finder = LRFinder(model, optimizer, criterion, device)\n",
        "# lrs, losses = lr_finder.range_test(train_iterator, END_LR, NUM_ITER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAr-csE4fh25"
      },
      "outputs": [],
      "source": [
        "# def plot_lr_finder(lrs, losses, skip_start = 5, skip_end = 5):\n",
        "    \n",
        "#     if skip_end == 0:\n",
        "#         lrs = lrs[skip_start:]\n",
        "#         losses = losses[skip_start:]\n",
        "#     else:\n",
        "#         lrs = lrs[skip_start:-skip_end]\n",
        "#         losses = losses[skip_start:-skip_end]\n",
        "    \n",
        "#     fig = plt.figure(figsize = (16,8))\n",
        "#     ax = fig.add_subplot(1,1,1)\n",
        "#     ax.plot(lrs, losses)\n",
        "#     ax.set_xscale('log')\n",
        "#     ax.set_xlabel('Learning rate')\n",
        "#     ax.set_ylabel('Loss')\n",
        "#     ax.grid(True, 'both', 'x')\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d08Pxxlzfo2F"
      },
      "outputs": [],
      "source": [
        "# plot_lr_finder(lrs, losses, skip_start = 0, skip_end = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd79wf2-fsRf"
      },
      "outputs": [],
      "source": [
        "FOUND_LR = 1e-2\n",
        "\n",
        "params = [\n",
        "          {'params': model.conv1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.bn1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
        "          {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
        "          {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
        "          {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
        "          {'params': model.fc.parameters()}\n",
        "         ]\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(params, lr = FOUND_LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOEvhuMdkBQJ"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_u-vV_Uh_wK"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20\n",
        "STEPS_PER_EPOCH = len(train_iterator)\n",
        "TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
        "\n",
        "MAX_LRS = [p['lr'] for p in optimizer.param_groups]\n",
        "\n",
        "scheduler = lr_scheduler.OneCycleLR(optimizer,\n",
        "                                    max_lr = MAX_LRS,\n",
        "                                    total_steps = TOTAL_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 10;"
      ],
      "metadata": {
        "id": "WN_SQ3YQLLHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBjRltzejxXv"
      },
      "outputs": [],
      "source": [
        "def calculate_topk_accuracy(y_pred, y, k = 2):\n",
        "    with torch.no_grad():\n",
        "        batch_size = y.shape[0]\n",
        "        bs = batch_size\n",
        "        _, top_pred = y_pred.topk(k, 1)\n",
        "        top_pred = top_pred.t()\n",
        "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
        "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
        "        acc_1 = correct_1 / batch_size\n",
        "        acc_k = correct_k / batch_size\n",
        "    return acc_1, acc_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbI4bWpJjyRk"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, scheduler, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_2 = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for (x, y) in iterator:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        y_pred, _ = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc_1, acc_2 = calculate_topk_accuracy(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc_1 += acc_1.item()\n",
        "        epoch_acc_2 += acc_2.item()\n",
        "        \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    epoch_acc_2 /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc_1, epoch_acc_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljis-zAKj_4Z"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            y_pred, _ = model(x)\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "            acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc_1 += acc_1.item()\n",
        "            epoch_acc_5 += acc_5.item()\n",
        "        \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    epoch_acc_5 /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc_1, epoch_acc_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P88dXbY8kGH6"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DEj_jtKkHX0",
        "outputId": "4dc7a6dd-cff9-40a0-dfa9-17ab5acad010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 2m 37s\n",
            "\tTrain Loss: 0.442 | Train Acc @1:  83.17% | Train Acc @2:  96.10%\n",
            "\tValid Loss: 0.313 | Valid Acc @1:  87.66% | Valid Acc @2:  97.36%\n",
            "Epoch: 02 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.322 | Train Acc @1:  87.75% | Train Acc @2:  97.70%\n",
            "\tValid Loss: 0.288 | Valid Acc @1:  89.01% | Valid Acc @2:  97.44%\n",
            "Epoch: 03 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.382 | Train Acc @1:  86.46% | Train Acc @2:  97.21%\n",
            "\tValid Loss: 0.372 | Valid Acc @1:  87.76% | Valid Acc @2:  97.24%\n",
            "Epoch: 04 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.397 | Train Acc @1:  86.98% | Train Acc @2:  97.36%\n",
            "\tValid Loss: 0.350 | Valid Acc @1:  88.60% | Valid Acc @2:  97.48%\n",
            "Epoch: 05 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.443 | Train Acc @1:  86.79% | Train Acc @2:  97.40%\n",
            "\tValid Loss: 0.478 | Valid Acc @1:  87.83% | Valid Acc @2:  97.42%\n",
            "Epoch: 06 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.506 | Train Acc @1:  86.23% | Train Acc @2:  97.25%\n",
            "\tValid Loss: 0.355 | Valid Acc @1:  89.54% | Valid Acc @2:  97.76%\n",
            "Epoch: 07 | Epoch Time: 2m 31s\n",
            "\tTrain Loss: 0.515 | Train Acc @1:  86.76% | Train Acc @2:  97.21%\n",
            "\tValid Loss: 0.633 | Valid Acc @1:  84.18% | Valid Acc @2:  95.63%\n",
            "Epoch: 08 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.479 | Train Acc @1:  87.89% | Train Acc @2:  97.38%\n",
            "\tValid Loss: 0.463 | Valid Acc @1:  87.60% | Valid Acc @2:  96.74%\n",
            "Epoch: 09 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.434 | Train Acc @1:  87.90% | Train Acc @2:  97.53%\n",
            "\tValid Loss: 0.653 | Valid Acc @1:  85.89% | Valid Acc @2:  97.94%\n",
            "Epoch: 10 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.404 | Train Acc @1:  88.41% | Train Acc @2:  97.72%\n",
            "\tValid Loss: 0.346 | Valid Acc @1:  89.66% | Valid Acc @2:  97.75%\n",
            "Epoch: 11 | Epoch Time: 2m 29s\n",
            "\tTrain Loss: 0.385 | Train Acc @1:  88.74% | Train Acc @2:  97.75%\n",
            "\tValid Loss: 1.536 | Valid Acc @1:  72.37% | Valid Acc @2:  92.07%\n",
            "Epoch: 12 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.371 | Train Acc @1:  89.23% | Train Acc @2:  97.81%\n",
            "\tValid Loss: 0.332 | Valid Acc @1:  89.66% | Valid Acc @2:  97.54%\n",
            "Epoch: 13 | Epoch Time: 2m 31s\n",
            "\tTrain Loss: 0.301 | Train Acc @1:  90.21% | Train Acc @2:  98.24%\n",
            "\tValid Loss: 0.329 | Valid Acc @1:  90.48% | Valid Acc @2:  97.76%\n",
            "Epoch: 14 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.285 | Train Acc @1:  90.64% | Train Acc @2:  98.35%\n",
            "\tValid Loss: 0.295 | Valid Acc @1:  91.05% | Valid Acc @2:  97.94%\n",
            "Epoch: 15 | Epoch Time: 2m 31s\n",
            "\tTrain Loss: 0.246 | Train Acc @1:  91.40% | Train Acc @2:  98.49%\n",
            "\tValid Loss: 0.261 | Valid Acc @1:  90.87% | Valid Acc @2:  98.02%\n",
            "Epoch: 16 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.247 | Train Acc @1:  91.26% | Train Acc @2:  98.49%\n",
            "\tValid Loss: 0.272 | Valid Acc @1:  91.82% | Valid Acc @2:  97.98%\n",
            "Epoch: 17 | Epoch Time: 2m 32s\n",
            "\tTrain Loss: 0.225 | Train Acc @1:  91.73% | Train Acc @2:  98.58%\n",
            "\tValid Loss: 0.241 | Valid Acc @1:  91.91% | Valid Acc @2:  98.14%\n",
            "Epoch: 18 | Epoch Time: 2m 30s\n",
            "\tTrain Loss: 0.202 | Train Acc @1:  92.50% | Train Acc @2:  98.90%\n",
            "\tValid Loss: 0.237 | Valid Acc @1:  92.08% | Valid Acc @2:  98.28%\n",
            "Epoch: 19 | Epoch Time: 2m 31s\n",
            "\tTrain Loss: 0.199 | Train Acc @1:  92.51% | Train Acc @2:  98.66%\n",
            "\tValid Loss: 0.235 | Valid Acc @1:  92.08% | Valid Acc @2:  98.15%\n",
            "Epoch: 20 | Epoch Time: 2m 31s\n",
            "\tTrain Loss: 0.201 | Train Acc @1:  92.64% | Train Acc @2:  98.84%\n",
            "\tValid Loss: 0.233 | Valid Acc @1:  92.00% | Valid Acc @2:  98.20%\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    train_loss, train_acc_1, train_acc_5 = train(model, train_iterator, optimizer, criterion, scheduler, device)\n",
        "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_iterator, criterion, device)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut5-model.pt')\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}% | ' \\\n",
        "          f'Train Acc @2: {train_acc_5*100:6.2f}%')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}% | ' \\\n",
        "          f'Valid Acc @2: {valid_acc_5*100:6.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3nUEkJ6kQma"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5H8620HkQNK",
        "outputId": "215bf773-7c77-4f96-8f6c-70d1607e5afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.496 | Test Acc @1:  84.36% | Test Acc @2:  96.55%\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut5-model.pt'))\n",
        "\n",
        "test_loss, test_acc_1, test_acc_5 = evaluate(model, test_iterator, criterion, device)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc @1: {test_acc_1*100:6.2f}% | ' \\\n",
        "      f'Test Acc @2: {test_acc_5*100:6.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vEoQddCHcNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d5cc1d-969d-4887-98eb-b8aaf0c0d59f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD5NPJYzJPmI"
      },
      "source": [
        "Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay1eA15VLe5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc009d7-2097-4be3-8245-4608ac7b2d1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Some standard imports\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.onnx\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input to the model\n",
        "x = torch.randn(bs, 3, 7, 7, requires_grad=True)\n",
        "model.to('cpu')\n",
        "torch_out = model(x)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model,               # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"output.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "metadata": {
        "id": "F8AHNGvTcSfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCPHjPEUjnXr",
        "outputId": "6f1c61f3-cd46-4b75-9de4-266ac7b78c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[ 0.0782,  0.2776,  0.7803],\n",
            "        [-0.1564,  0.1292,  0.5716],\n",
            "        [-0.2011,  0.1668,  0.6258],\n",
            "        [ 0.1239,  0.4531,  0.6995],\n",
            "        [-0.0147,  0.3615,  0.7478],\n",
            "        [-0.0012,  0.5690,  0.7569],\n",
            "        [-0.0857,  0.7378,  0.6964],\n",
            "        [ 0.0546,  0.3997,  0.6533],\n",
            "        [ 0.0438,  0.2617,  0.3185],\n",
            "        [-0.0398,  0.3323,  0.4207]], grad_fn=<AddmmBackward0>), tensor([[0.0000, 0.2091, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.2360, 0.0000, 0.3891,  ..., 0.0000, 0.1304, 0.1135],\n",
            "        [0.1077, 0.0000, 0.0000,  ..., 0.0438, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.1828, 0.0000, 0.0000,  ..., 0.3704, 0.2031, 0.0000],\n",
            "        [0.0601, 0.0000, 0.0000,  ..., 0.0843, 0.0687, 0.1060],\n",
            "        [0.0556, 0.0000, 0.0000,  ..., 0.0275, 0.0000, 0.0000]],\n",
            "       grad_fn=<ViewBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJPY0FiwMj6r"
      },
      "source": [
        "Test ONNX Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_TMxl-8Mjl6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "9d96bcb1-8430-4696-9832-92088065606f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-6503f7e07ee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# compare ONNX Runtime and PyTorch results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mort_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exported model has been tested with ONNXRuntime, and the result looks good!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-6503f7e07ee1>\u001b[0m in \u001b[0;36mto_numpy\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# compute ONNX Runtime output prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'requires_grad'"
          ]
        }
      ],
      "source": [
        "#!pip install onnxruntime\n",
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"output.onnx\")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor[:].detach().cpu().numpy() if tensor[:].requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONNX TO TENSORFLOW"
      ],
      "metadata": {
        "id": "ToNpQw2-ia1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx_tf\n",
        "from onnx_tf.backend import prepare\n",
        "import onnx\n",
        "\n",
        "TF_PATH = \"./converted.pb\" # where the representation of tensorflow model will be stored\n",
        "ONNX_PATH = \"./converted.onnx\" # path to my existing ONNX model\n",
        "onnx_model = onnx.load(ONNX_PATH)  # load onnx model\n",
        "\n",
        "# prepare function converts an ONNX model to an internel representation\n",
        "# of the computational graph called TensorflowRep and returns\n",
        "# the converted representation.\n",
        "tf_rep = prepare(onnx_model)  # creating TensorflowRep object\n",
        "\n",
        "# export_graph function obtains the graph proto corresponding to the ONNX\n",
        "# model associated with the backend representation and serializes\n",
        "# to a protobuf file.\n",
        "tf_rep.export_graph(TF_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8itH_X7OiaKB",
        "outputId": "845638e1-71fe-447b-b4c7-d35effafeb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx_tf\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[K     || 226 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     || 1.1 MB 80.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from onnx_tf) (3.13)\n",
            "Requirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.7/dist-packages (from onnx_tf) (1.12.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.10.2->onnx_tf) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.10.2->onnx_tf) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.10.2->onnx_tf) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.12.2->onnx>=1.10.2->onnx_tf) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->onnx_tf) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->onnx_tf) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons->onnx_tf) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons, onnx-tf\n",
            "Successfully installed onnx-tf-1.10.0 tensorflow-addons-0.17.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(TF_PATH) # path to the SavedModel directory\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "model_name = \"classification\"\n",
        "\n",
        "# Save the model.\n",
        "with open(model_name +\".tflite\", \"wb\") as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQxXX98pit2a",
        "outputId": "78019a2d-4276-4f78-8537-325566762fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-colab\n",
        "from google.colab import files\n",
        "files.download('classification.tflite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oxf8jZX4i_lH",
        "outputId": "9b9bfbf7-15a7-47c4-b655-442d268880e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from google-colab) (1.35.0)\n",
            "Requirement already satisfied: requests~=2.23.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (2.23.0)\n",
            "Requirement already satisfied: tornado~=5.1.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (5.1.1)\n",
            "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.7/dist-packages (from google-colab) (1.3.9)\n",
            "Requirement already satisfied: ipykernel~=4.10 in /usr/local/lib/python3.7/dist-packages (from google-colab) (4.10.1)\n",
            "Requirement already satisfied: astor~=0.8.1 in /usr/local/lib/python3.7/dist-packages (from google-colab) (0.8.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (1.3.5)\n",
            "Requirement already satisfied: ipython~=5.5.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (5.5.0)\n",
            "Requirement already satisfied: notebook~=5.3.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (5.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab) (4.2.4)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel~=4.10->google-colab) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel~=4.10->google-colab) (5.3.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (5.4.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (4.11.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (0.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel~=4.10->google-colab) (23.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel~=4.10->google-colab) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->google-colab) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->google-colab) (2022.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython~=5.5.0->google-colab) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.17.2->google-colab) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab) (2.10)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook~=5.3.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook~=5.3.0->google-colab) (2.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (5.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (0.6.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook~=5.3.0->google-colab) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook~=5.3.0->google-colab) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (4.1.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (5.8.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (3.8.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook~=5.3.0->google-colab) (0.5.1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_155380aa-d5df-4beb-b492-be78159d8fe1\", \"classification.tflite\", 93979632)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r56Odc_kkH9"
      },
      "source": [
        "# Examination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgZCvPA1mFlg"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbu1v4lxkf7b"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, iterator):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "\n",
        "            y_pred, _ = model(x)\n",
        "\n",
        "            y_prob = F.softmax(y_pred, dim = -1)\n",
        "            top_pred = y_prob.argmax(1, keepdim = True)\n",
        "\n",
        "            images.append(x.cpu())\n",
        "            labels.append(y.cpu())\n",
        "            probs.append(y_prob.cpu())\n",
        "\n",
        "    images = torch.cat(images, dim = 0)\n",
        "    labels = torch.cat(labels, dim = 0)\n",
        "    probs = torch.cat(probs, dim = 0)\n",
        "\n",
        "    return images, labels, probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgeM5KCWknSY"
      },
      "outputs": [],
      "source": [
        "images, labels, probs = get_predictions(model, test_iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx2JcUwTkoA7"
      },
      "outputs": [],
      "source": [
        "pred_labels = torch.argmax(probs, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vmOdwvFkozr"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(labels, pred_labels, classes):\n",
        "    \n",
        "    fig = plt.figure(figsize = (50, 50));\n",
        "    ax = fig.add_subplot(1, 1, 1);\n",
        "    cm = confusion_matrix(labels, pred_labels);\n",
        "    cm = ConfusionMatrixDisplay(cm, display_labels = classes);\n",
        "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
        "    fig.delaxes(fig.axes[1]) #delete colorbar\n",
        "    plt.xticks(rotation = 90)\n",
        "    plt.xlabel('Predicted Label', fontsize = 50)\n",
        "    plt.ylabel('True Label', fontsize = 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOzL4NVTkx_x"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioc6tX4mlv3-"
      },
      "source": [
        "# Most Incorrect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfE0iOzKkt5r"
      },
      "outputs": [],
      "source": [
        "corrects = torch.eq(labels, pred_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-5lZHPSk2kk"
      },
      "outputs": [],
      "source": [
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, corrects):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nrjyv95Mk371"
      },
      "outputs": [],
      "source": [
        "def plot_most_incorrect(incorrect, classes, n_images, normalize = True):\n",
        "\n",
        "    rows = int(np.sqrt(n_images))\n",
        "    cols = int(np.sqrt(n_images))\n",
        "\n",
        "    fig = plt.figure(figsize = (25, 20))\n",
        "\n",
        "    for i in range(rows*cols):\n",
        "\n",
        "        ax = fig.add_subplot(rows, cols, i+1)\n",
        "        \n",
        "        image, true_label, probs = incorrect[i]\n",
        "        image = image.permute(1, 2, 0)\n",
        "        true_prob = probs[true_label]\n",
        "        incorrect_prob, incorrect_label = torch.max(probs, dim = 0)\n",
        "        true_class = classes[true_label]\n",
        "        incorrect_class = classes[incorrect_label]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax.imshow(image.cpu().numpy())\n",
        "        ax.set_title(f'true label: {true_class} ({true_prob:.3f})\\n' \\\n",
        "                     f'pred label: {incorrect_class} ({incorrect_prob:.3f})')\n",
        "        ax.axis('off')\n",
        "        \n",
        "    fig.subplots_adjust(hspace=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgUNisKqk6oB"
      },
      "outputs": [],
      "source": [
        "N_IMAGES = 25\n",
        "\n",
        "plot_most_incorrect(incorrect_examples, classes, N_IMAGES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2isiM8krlpyU"
      },
      "source": [
        "# Representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smQOG-oGlIBF"
      },
      "outputs": [],
      "source": [
        "def get_representations(model, iterator):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    outputs = []\n",
        "    intermediates = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "\n",
        "            y_pred, _ = model(x)\n",
        "\n",
        "            outputs.append(y_pred.cpu())\n",
        "            labels.append(y)\n",
        "        \n",
        "    outputs = torch.cat(outputs, dim = 0)\n",
        "    labels = torch.cat(labels, dim = 0)\n",
        "\n",
        "    return outputs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZKk870tlJGZ"
      },
      "outputs": [],
      "source": [
        "outputs, labels = get_representations(model, train_iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfqZcyCQlKSh"
      },
      "outputs": [],
      "source": [
        "def get_pca(data, n_components = 2):\n",
        "    pca = decomposition.PCA()\n",
        "    pca.n_components = n_components\n",
        "    pca_data = pca.fit_transform(data)\n",
        "    return pca_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATt5zsELlL3T"
      },
      "outputs": [],
      "source": [
        "def plot_representations(data, labels, classes, n_images = None):\n",
        "            \n",
        "    if n_images is not None:\n",
        "        data = data[:n_images]\n",
        "        labels = labels[:n_images]\n",
        "                \n",
        "    fig = plt.figure(figsize = (15, 15))\n",
        "    ax = fig.add_subplot(111)\n",
        "    scatter = ax.scatter(data[:, 0], data[:, 1], c = labels, cmap = 'hsv')\n",
        "    handles, _ = scatter.legend_elements(num = None)\n",
        "    legend = plt.legend(handles = handles, labels = classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV2qYJEolPuI"
      },
      "outputs": [],
      "source": [
        "output_pca_data = get_pca(outputs)\n",
        "plot_representations(output_pca_data, labels, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b45QIvoVlSmD"
      },
      "outputs": [],
      "source": [
        "def get_tsne(data, n_components = 2, n_images = None):\n",
        "    \n",
        "    if n_images is not None:\n",
        "        data = data[:n_images]\n",
        "        \n",
        "    tsne = manifold.TSNE(n_components = n_components, random_state = 0)\n",
        "    tsne_data = tsne.fit_transform(data)\n",
        "    return tsne_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68UjAM0BlUsn"
      },
      "outputs": [],
      "source": [
        "output_tsne_data = get_tsne(outputs)\n",
        "plot_representations(output_tsne_data, labels, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IWFC5FKliRb"
      },
      "source": [
        "# Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV7m7MmNlWY6"
      },
      "outputs": [],
      "source": [
        "def plot_filtered_images(images, filters, n_filters = None, normalize = True):\n",
        "\n",
        "    images = torch.cat([i.unsqueeze(0) for i in images], dim = 0).cpu()\n",
        "    filters = filters.cpu()\n",
        "\n",
        "    if n_filters is not None:\n",
        "        filters = filters[:n_filters]\n",
        "\n",
        "    n_images = images.shape[0]\n",
        "    n_filters = filters.shape[0]\n",
        "\n",
        "    filtered_images = F.conv2d(images, filters)\n",
        "\n",
        "    fig = plt.figure(figsize = (30, 30))\n",
        "\n",
        "    for i in range(n_images):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax = fig.add_subplot(n_images, n_filters+1, i+1+(i*n_filters))\n",
        "        ax.imshow(image.permute(1,2,0).numpy())\n",
        "        ax.set_title('Original')\n",
        "        ax.axis('off')\n",
        "\n",
        "        for j in range(n_filters):\n",
        "            image = filtered_images[i][j]\n",
        "\n",
        "            if normalize:\n",
        "                image = normalize_image(image)\n",
        "\n",
        "            ax = fig.add_subplot(n_images, n_filters+1, i+1+(i*n_filters)+j+1)\n",
        "            ax.imshow(image.numpy(), cmap = 'bone')\n",
        "            ax.set_title(f'Filter {j+1}')\n",
        "            ax.axis('off');\n",
        "\n",
        "    fig.subplots_adjust(hspace = -0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tUdSvaxlZZr"
      },
      "outputs": [],
      "source": [
        "N_IMAGES = 5\n",
        "N_FILTERS = 7\n",
        "\n",
        "images = [image for image, label in [train_data[i] for i in range(N_IMAGES)]]\n",
        "filters = model.conv1.weight.data\n",
        "\n",
        "plot_filtered_images(images, filters, N_FILTERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruKyiY8Gldq1"
      },
      "outputs": [],
      "source": [
        "def plot_filters(filters, normalize = True):\n",
        "\n",
        "    filters = filters.cpu()\n",
        "\n",
        "    n_filters = filters.shape[0]\n",
        "\n",
        "    rows = int(np.sqrt(n_filters))\n",
        "    cols = int(np.sqrt(n_filters))\n",
        "\n",
        "    fig = plt.figure(figsize = (30, 15))\n",
        "\n",
        "    for i in range(rows*cols):\n",
        "\n",
        "        image = filters[i]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax = fig.add_subplot(rows, cols, i+1)\n",
        "        ax.imshow(image.permute(1, 2, 0))\n",
        "        ax.axis('off')\n",
        "        \n",
        "    fig.subplots_adjust(wspace = -0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzaO8lj8lex_"
      },
      "outputs": [],
      "source": [
        "plot_filters(filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqcOevxskTuS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3IFG9ogbhqAN",
        "XL0q-TPtjblF",
        "xKLalPFZad_D",
        "ZIdcGfYmiBJv",
        "4r56Odc_kkH9",
        "ioc6tX4mlv3-",
        "2isiM8krlpyU",
        "3IWFC5FKliRb"
      ],
      "name": "Image Classification - ResNet50 x Waste Classification Data v2 ",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "971af6b9eb044275a29e83c76126c572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2291a6be364f4d63b37d8b8e3e636766",
              "IPY_MODEL_c5b7a7bfd40e4a158e0b70a3e7e0988f",
              "IPY_MODEL_c4728cb6e25f42e7bcc8eaec072c420a"
            ],
            "layout": "IPY_MODEL_5473d9ddbd06425c909e3b1815d877d3"
          }
        },
        "2291a6be364f4d63b37d8b8e3e636766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f709c7b385c14941a2941db586d8c677",
            "placeholder": "",
            "style": "IPY_MODEL_1e53c5a33b524b9dac7f8b7962e1cf30",
            "value": "100%"
          }
        },
        "c5b7a7bfd40e4a158e0b70a3e7e0988f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef0fe32be564abe804987a498a7fcd6",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe373a67416249dab8acbc0b213c7416",
            "value": 102530333
          }
        },
        "c4728cb6e25f42e7bcc8eaec072c420a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5a86dd671d949fcaa76922a43477c69",
            "placeholder": "",
            "style": "IPY_MODEL_7645f7f1521440b48e4e678f5bf65912",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 259MB/s]"
          }
        },
        "5473d9ddbd06425c909e3b1815d877d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f709c7b385c14941a2941db586d8c677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e53c5a33b524b9dac7f8b7962e1cf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef0fe32be564abe804987a498a7fcd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe373a67416249dab8acbc0b213c7416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5a86dd671d949fcaa76922a43477c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7645f7f1521440b48e4e678f5bf65912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}